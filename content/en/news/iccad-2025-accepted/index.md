---
title: Four Papers and One Special Session Accepted by ICCAD'2025
subtitle: Four papers on efficient AI are accepted by ICCAD'2025 as regular papers. We are also organizing a special session on privacy-preserving AI.

#subtitle: Seven papers on efficient and privacy-preserving deep learning are accepted by ICCAD'2024 as regular papers, including "OSCA&#58; End-to-end Serial Stochastic Computing Neural Acceleration with Fine-grained Scaling and Piecewise Activation", "HG-PIPE&#58; Vision Transformer Acceleration with Hybrid-Grained Pipeline", "ProPD&#58; Dynamic Token Tree Pruning and Generation for LLM Parallel Decoding", "AdapMoE&#58; Adaptive Sensitivity-based Expert Gating and Management for Efficient MoE Inference", "MCUBERT&#58; Memory-Efficient BERT Inference on Commodity Microcontrollers", "PrivQuant&#58; Communication-Efficient Private Inference with Quantized Network/Protocol Co-Optimization", and "FlexHE&#58; A flexible Kernel Generation Framework for Homomorphic Encryption-Based Private Inference".

# Summary for listings and search engines
# summary: Seven papers on efficient and privacy-preserving deep learning are accepted by ICCAD'2024 as regular papers, including "OSCA&#58; End-to-end Serial Stochastic Computing Neural Acceleration with Fine-grained Scaling and Piecewise Activation", "HG-PIPE&#58; Vision Transformer Acceleration with Hybrid-Grained Pipeline", "ProPD&#58; Dynamic Token Tree Pruning and Generation for LLM Parallel Decoding", "AdapMoE&#58; Adaptive Sensitivity-based Expert Gating and Management for Efficient MoE Inference", "MCUBERT&#58; Memory-Efficient BERT Inference on Commodity Microcontrollers", "PrivQuant&#58; Communication-Efficient Private Inference with Quantized Network/Protocol Co-Optimization", and "FlexHE&#58; A flexible Kernel Generation Framework for Homomorphic Encryption-Based Private Inference".
summary: Four papers on efficient AI and one special session proposal on privacy-preserving AI are accepted by ICCAD'2025.

# Date published
date: "2025-06-27T00:00:00Z"

# Date updated
lastmod: "2025-06-27T00:00:00Z"

# Is this an unpublished draft?
draft: false

# Show this page in the Featured widget?
featured: true

tags:
- Conference
---

Papers on efficient AI:
- No Redundancy, No Stall: Lightweight Streaming 3D Gaussian Splatting for Real-time Rendering
- H2EAL: Hybrid-Bonding Architecture with Hybrid Sparse Attention for Efficient Long-Context LLM Inference
- HD-MoE: Hybrid and Dynamic Parallelism for Mixture-of-Expert LLMs with 3D Near-Memory Processing
- SpecMamba: Accelerating Mamba Inference on FPGA with Speculative Decoding
